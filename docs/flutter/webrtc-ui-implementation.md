# Flutter WebRTC UI Implementation Guide

**Project:** SecureConnect SaaS Platform  
**Version:** 1.0  
**Status:** Draft  
**Author:** System Architect

## 16.1. T·ªïng quan

M√†n h√¨nh Video Call (Flutter) ch·ªãu tr√°ch nhi·ªám:
1.  K·∫øt n·ªëi Media Device (Camera/Microphone).
2.  T·∫°o `RTCPeerConnection` ƒë·ªÉ k·∫øt n·ªëi P2P ho·∫∑c SFU.
3.  Giao ti·∫øp Signaling (SDP Offer/Answer, ICE Candidate) v·ªõi Backend Go qua WebSocket.
4.  Hi·ªÉn th·ªã lu·ªìng video Local v√† Remote.
5.  X·ª≠ l√Ω c√°c ƒëi·ªÅu khi·ªÉn (Mute, Camera, Share Screen).

---

## 16.2. C√†i ƒë·∫∑t Dependencies

Th√™m v√†o `pubspec.yaml`:

```yaml
dependencies:
  flutter:
    sdk: flutter

  # WebRTC Core
  flutter_webrtc: ^0.9.40
  permission_handler: ^11.0.0 # X·ª≠ l√Ω quy·ªÅn Camera/Mic tr√™n Mobile

  # UI Utils
  flutter_bloc: ^8.1.3 # Ho·∫∑c flutter_riverpod (n·∫øu d√πng chung)
  flutter_screenutil: ^5.8.4 # Responsive UI
  lottie: ^2.6.0 # Animation cho tr·∫°ng th√°i ƒëang g·ªçi
```

### C·∫•u h√¨nh quy·ªÅn (Permissions)

**Android (`android/app/src/main/AndroidManifest.xml`):**
```xml
<uses-permission android:name="android.permission.INTERNET"/>
<uses-permission android:name="android.permission.CAMERA"/>
<uses-permission android:name="android.permission.RECORD_AUDIO"/>
<uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS"/>
<uses-permission android:name="android.permission.WAKE_LOCK"/>
<uses-permission android:name="android.permission.BLUETOOTH"/>
```

**iOS (`ios/Runner/Info.plist`):**
```xml
<key>NSCameraUsageDescription</key>
<string>·ª®ng d·ª•ng c·∫ßn quy·ªÅn truy c·∫≠p Camera ƒë·ªÉ g·ªçi Video</string>
<key>NSMicrophoneUsageDescription</key>
<string>·ª®ng d·ª•ng c·∫ßn quy·ªÅn truy c·∫≠p Micro ƒë·ªÉ nghe gi·ªçng n√≥i</string>
```

---

## 16.3. Ki·∫øn tr√∫c Th∆∞ m·ª•c (Project Structure)

```bash
lib/features/call/
‚îú‚îÄ‚îÄ presentation/
‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ video_call_page.dart       # M√†n h√¨nh ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ widgets/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ local_video_view.dart     # Video c·ªßa m√¨nh
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ remote_video_view.dart    # Video ng∆∞·ªùi kh√°c
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ call_controls.dart        # N√∫t b·∫•m ƒëi·ªÅu khi·ªÉn
‚îÇ   ‚îî‚îÄ‚îÄ providers/
‚îÇ       ‚îî‚îÄ‚îÄ call_state_provider.dart # State Management (Bloc/Riverpod)
‚îú‚îÄ‚îÄ domain/
‚îÇ   ‚îî‚îÄ‚îÄ entities/
‚îÇ       ‚îî‚îÄ‚îÄ call_state.dart
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ services/
        ‚îú‚îÄ‚îÄ webrtc_manager.dart       # Logic WebRTC Core
        ‚îî‚îÄ‚îÄ signaling_client.dart     # WebSocket Client
```

---

## 16.4. WebRTC Manager (Logic Core)

L·ªõp n√†y ƒë√≥ng g√≥i logic ph·ª©c t·∫°p c·ªßa `flutter_webrtc`, gi√∫p UI s·∫°ch s·∫Ω.

**File: `lib/features/call/data/services/webrtc_manager.dart`**

```dart
import 'package:flutter/foundation.dart';
import 'package:flutter_webrtc/flutter_webrtc.dart';
import 'package:uuid/uuid.dart';

class WebRTCManager {
  // Peer Connection
  RTCPeerConnection? _peerConnection;
  
  // Streams
  MediaStream? _localStream;
  List<MediaStream> _remoteStreams = [];
  
  // Renderers
  final _localRenderer = RTCVideoRenderer();
  final _remoteRenderer = RTCVideoRenderer();
  
  // Config
  final Map<String, dynamic> _iceServers;

  // Callbacks cho UI
  Function(RTCVideoRenderer)? onLocalStreamReady;
  Function(RTCVideoRenderer)? onRemoteStreamReady;
  Function(String)? onIceCandidate;
  Function(RTCSessionDescription)? onSignalingMessage; // Send SDP Offer/Answer

  WebRTCManager(this._iceServers);

  // 1. Kh·ªüi t·∫°o Local Stream (Camera/Mic)
  Future<void> initLocalStream({bool audio = true, bool video = true}) async {
    final Map<String, dynamic> constraints = {
      'audio': audio,
      'video': video
        ? {
            'facingMode': 'user', // Camera tr∆∞·ªõc
            'width': {'ideal': 1280},
            'height': {'ideal': 720}
          }
        : false
    };

    try {
      _localStream = await navigator.mediaDevices.getUserMedia(constraints);
      _localRenderer.srcObject = _localStream;
      
      // Notify UI
      onLocalStreamReady?.call(_localRenderer);
    } catch (e) {
      debugPrint('Error accessing media devices: $e');
      rethrow;
    }
  }

  // 2. T·∫°o Peer Connection
  Future<void> createPeerConnection() async {
    final configuration = RTCConfiguration(
      iceServers: [
        RTCIceServer(url: "stun:stun.l.google.com:19302"),
        ...(_iceServers['turn_servers'] ?? []).map((e) => RTCIceServer(
            url: e['url'],
            username: e['username'],
            credential: e['credential']
        ))
      ],
    );

    _peerConnection = await createPeerConnection(configuration);

    // X·ª≠ l√Ω ICE Candidate
    _peerConnection!.onIceCandidate = (candidate) {
      if (candidate == null) return;
      // G·ª≠i qua WebSocket Signaling
      onIceCandidate?.call(candidate.toMap());
    };

    // X·ª≠ l√Ω Remote Stream (Khi ng∆∞·ªùi kh√°c g·ª≠i video)
    _peerConnection!.onTrack = (event) {
      if (event.track.kind == 'video' || event.track.kind == 'audio') {
        // N·∫øu l√† video, render ra
        if (event.streams.isNotEmpty) {
          final remoteStream = event.streams[0];
          if (!_remoteStreams.contains(remoteStream)) {
            _remoteStreams.add(remoteStream);
            _remoteRenderer.srcObject = remoteStream;
            onRemoteStreamReady?.call(_remoteRenderer);
          }
        }
      }
    };
    
    // X·ª≠ l√Ω thay ƒë·ªïi tr·∫°ng th√°i k·∫øt n·ªëi
    _peerConnection!.onConnectionState = (state) {
      debugPrint('Connection State: ${state.name}');
    };
  }

  // 3. T·∫°o Offer (G·ªçi ƒëi)
  Future<RTCSessionDescription> createOffer(String callId) async {
    final offer = await _peerConnection!.createOffer();
    await _peerConnection!.setLocalDescription(offer);
    return offer;
  }

  // 4. X·ª≠ l√Ω Offer (Nh·∫≠n cu·ªôc g·ªçi)
  Future<void> handleOffer(RTCSessionDescription offer) async {
    await _peerConnection!.setRemoteDescription(offer);
    
    // T·∫°o Answer
    final answer = await _peerConnection!.createAnswer();
    await _peerConnection!.setLocalDescription(answer);
    
    // Tr·∫£ Answer v·ªÅ Signaling
    onSignalingMessage?.call(answer);
  }

  // 5. X·ª≠ l√Ω Answer
  Future<void> handleAnswer(RTCSessionDescription answer) async {
    await _peerConnection!.setRemoteDescription(answer);
  }

  // 6. Th√™m ICE Candidate nh·∫≠n ƒë∆∞·ª£c t·ª´ Server
  Future<void> addCandidate(Map<String, dynamic> candidateMap) async {
    final candidate = RTCIceCandidate(candidateMap);
    await _peerConnection!.addCandidate(candidate);
  }

  // --- CONTROLS ---
  
  // B·∫≠t/T·∫Øt Microphone
  void toggleAudio(bool enabled) {
    _localStream?.getAudioTracks().forEach((track) => track.enabled = enabled);
  }

  // B·∫≠t/T·∫Øt Camera
  void toggleVideo(bool enabled) {
    _localStream?.getVideoTracks().forEach((track) => track.enabled = enabled);
  }

  // Chuy·ªÉn Camera (Front <-> Back)
  Future<void> switchCamera() async {
    if (_localStream != null) {
      final videoTrack = _localStream!.getVideoTracks()[0];
      // Helper method ƒë·ªÉ switch track trong flutter_webrtc
      await Helper.switchCamera(videoTrack);
    }
  }
  
  // K·∫øt th√∫c cu·ªôc g·ªçi
  Future<void> dispose() async {
    _localStream?.getTracks().forEach((track) => track.stop());
    await _localRenderer.dispose();
    await _remoteRenderer.dispose();
    await _peerConnection?.close();
    _peerConnection = null;
  }
}
```

---

## 16.5. Signaling Client (WebSocket)

K·∫øt n·ªëi v·ªõi `wss://api.secureconnect.com/v1/ws/signaling`.

**File: `lib/features/call/data/services/signaling_client.dart`**

```dart
import 'dart:async';
import 'dart:convert';
import 'package:web_socket_channel/web_socket_channel.dart';

class SignalingClient {
  final String _wsUrl;
  WebSocketChannel? _channel;
  final Function(Map<String, dynamic>) _onMessage;

  SignalingClient(this._wsUrl, this._onMessage);

  void connect() {
    _channel = WebSocketChannel.connect(Uri.parse(_wsUrl));
    
    _channel!.stream.listen(
      (message) {
        final data = jsonDecode(message);
        _onMessage(data);
      },
      onError: (error) => print('WS Error: $error'),
      onDone: () => print('WS Closed'),
    );
  }

  void send(Map<String, dynamic> payload) {
    _channel?.sink.add(jsonEncode(payload));
  }

  void close() {
    _channel?.sink.close();
  }
}
```

---

## 16.6. State Management (Riverpod/Bloc)

Qu·∫£n l√Ω tr·∫°ng th√°i cu·ªôc g·ªçi (Ringing -> Connected -> Ended).

**File: `lib/features/call/presentation/providers/call_state_provider.dart` (D√πng Riverpod v√≠ d·ª•)**

```dart
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter_webrtc/flutter_webrtc.dart';
import '../../data/services/webrtc_manager.dart';

enum CallStatus { idle, ringing, connected, ended, failed }

class CallState {
  final CallStatus status;
  final RTCVideoRenderer? localRenderer;
  final RTCVideoRenderer? remoteRenderer;
  final bool isAudioEnabled;
  final bool isVideoEnabled;
  final bool isEncrypted; // E2EE Mode

  CallState({
    required this.status,
    this.localRenderer,
    this.remoteRenderer,
    this.isAudioEnabled = true,
    this.isVideoEnabled = true,
    this.isEncrypted = true,
  });

  CallState copyWith({
    CallStatus? status,
    RTCVideoRenderer? localRenderer,
    RTCVideoRenderer? remoteRenderer,
    bool? isAudioEnabled,
    bool? isVideoEnabled,
    bool? isEncrypted,
  }) {
    return CallState(
      status: status ?? this.status,
      localRenderer: localRenderer ?? this.localRenderer,
      remoteRenderer: remoteRenderer ?? this.remoteRenderer,
      isAudioEnabled: isAudioEnabled ?? this.isAudioEnabled,
      isVideoEnabled: isVideoEnabled ?? this.isVideoEnabled,
      isEncrypted: isEncrypted ?? this.isEncrypted,
    );
  }
}

class CallNotifier extends StateNotifier<CallState> {
  late WebRTCManager _webrtcManager;
  late SignalingClient _signalingClient;
  late String _callId;

  CallNotifier() : super(CallState(status: CallStatus.idle));

  Future<void> startCall(String callId, Map<String, dynamic> iceServers, bool isEncrypted) async {
    _callId = callId;
    state = state.copyWith(isEncrypted: isEncrypted, status: CallStatus.ringing);

    // 1. Init WebRTC
    _webrtcManager = WebRTCManager(iceServers);
    await _webrtcManager.initLocalStream();
    await _webrtcManager.createPeerConnection();

    // Setup Callbacks
    _webrtcManager.onLocalStreamReady = (renderer) {
      state = state.copyWith(localRenderer: renderer);
    };
    _webrtcManager.onRemoteStreamReady = (renderer) {
      state = state.copyWith(remoteRenderer: renderer, status: CallStatus.connected);
    };
    
    // 2. Setup Signaling
    final token = '...'; // Get from Auth Provider
    _signalingClient = SignalingClient(
      'wss://api.secureconnect.com/v1/ws/signaling?token=$token',
      _handleSignalingMessage
    );
    _signalingClient.connect();

    // 3. Create Offer & Send
    final offer = await _webrtcManager.createOffer(callId);
    _signalingClient.send({
      'type': 'offer',
      'call_id': callId,
      'sdp': offer.sdp,
    });
  }

  void _handleSignalingMessage(Map<String, dynamic> msg) {
    switch (msg['type']) {
      case 'answer':
        final desc = RTCSessionDescription(msg['sdp'], 'answer');
        _webrtcManager.handleAnswer(desc);
        break;
      case 'ice_candidate':
        _webrtcManager.addCandidate(msg['candidate']);
        break;
      case 'user_joined':
        // X·ª≠ l√Ω logic hi·ªÉn th·ªã ng∆∞·ªùi tham gia
        break;
    }
  }

  void toggleAudio() {
    _webrtcManager.toggleAudio(!state.isAudioEnabled);
    state = state.copyWith(isAudioEnabled: !state.isAudioEnabled);
  }

  void endCall() async {
    _signalingClient.send({'type': 'leave', 'call_id': _callId});
    await _webrtcManager.dispose();
    state = CallState(status: CallStatus.ended);
  }
}

final callProvider =
    StateNotifierProvider<CallNotifier, CallState>((ref) => CallNotifier());
```

---

## 16.7. UI Implementation (Video Call Page)

S·ª≠ d·ª•ng `RTCVideoRendererView` ƒë·ªÉ hi·ªÉn th·ªã video v√† `Stack` ƒë·ªÉ x·∫øp Local l√™n tr√™n Remote.

**File: `lib/features/call/presentation/pages/video_call_page.dart`**

```dart
import 'package:flutter/material.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter_webrtc/flutter_webrtc.dart';
import 'providers/call_state_provider.dart';

class VideoCallPage extends ConsumerWidget {
  final String callId;
  final Map<String, dynamic> iceServers;
  final bool isEncrypted; // From settings/conversation metadata

  const VideoCallPage({
    super.key,
    required this.callId,
    required this.iceServers,
    required this.isEncrypted,
  });

  @override
  Widget build(BuildContext context, WidgetRef ref) {
    final callState = ref.watch(callProvider);
    
    // Auto start when widget init
    WidgetsBinding.instance.addPostFrameCallback((_) {
      ref.read(callProvider.notifier).startCall(callId, iceServers, isEncrypted);
    });

    return Scaffold(
      backgroundColor: Colors.black,
      appBar: AppBar(
        backgroundColor: Colors.transparent,
        elevation: 0,
        actions: [
          if (!isEncrypted)
            const Padding(
              padding: EdgeInsets.all(8.0),
              child: Chip(
                label: Text("AI Mode Active", style: TextStyle(color: Colors.black)),
                backgroundColor: Colors.red,
              ),
            ),
          IconButton(
            icon: const Icon(Icons.switch_camera, color: Colors.white),
            onPressed: () => ref.read(callProvider.notifier).switchCamera(),
          ),
        ],
      ),
      body: Stack(
        children: [
          // 1. REMOTE VIDEO (N·ªÅn)
          if (callState.remoteRenderer != null)
            Center(
              child: RTCVideoView(
                callState.remoteRenderer!,
                objectFit: RTCVideoViewObjectFit.RTCVideoViewObjectFitCover,
              ),
            )
          else
            const Center(child: CircularProgressIndicator()),

          // 2. LOCAL VIDEO (G√≥c ph·∫£i - PiP)
          if (callState.localRenderer != null)
            Positioned(
              top: 20,
              right: 20,
              width: 120,
              height: 160,
              child: ClipRRect(
                borderRadius: BorderRadius.circular(12),
                child: RTCVideoView(
                  callState.localRenderer!,
                  mirror: true, // G∆∞∆°ng cho camera tr∆∞·ªõc
                  objectFit: RTCVideoViewObjectFit.RTCVideoViewObjectFitCover,
                ),
              ),
            ),

          // 3. CONTROLS (Thanh d∆∞·ªõi)
          if (callState.status == CallStatus.connected)
            Align(
              alignment: Alignment.bottomCenter,
              child: Container(
                margin: const EdgeInsets.only(bottom: 30),
                padding: const EdgeInsets.symmetric(horizontal: 20, vertical: 15),
                decoration: BoxDecoration(
                  color: Colors.grey[800]!.withOpacity(0.7),
                  borderRadius: BorderRadius.circular(30),
                ),
                child: Row(
                  mainAxisAlignment: MainAxisAlignment.spaceEvenly,
                  children: [
                    // Mute Audio
                    ControlButton(
                      icon: callState.isAudioEnabled ? Icons.mic : Icons.mic_off,
                      onTap: () => ref.read(callProvider.notifier).toggleAudio(),
                      color: callState.isAudioEnabled ? Colors.white : Colors.red,
                    ),
                    // Mute Video
                    ControlButton(
                      icon: callState.isVideoEnabled ? Icons.videocam : Icons.videocam_off,
                      onTap: () => ref.read(callProvider.notifier).toggleVideo(),
                      color: callState.isVideoEnabled ? Colors.white : Colors.red,
                    ),
                    // End Call
                    ControlButton(
                      icon: Icons.call_end,
                      onTap: () {
                        ref.read(callProvider.notifier).endCall();
                        Navigator.pop(context);
                      },
                      color: Colors.red,
                      isEndCall: true,
                    ),
                    // Screen Share (Placeholder logic)
                    ControlButton(
                      icon: Icons.screen_share,
                      onTap: () => print("Screen Share"),
                      color: Colors.white,
                    ),
                  ],
                ),
              ),
            ),
        ],
      ),
    );
  }
}

// Widget n√∫t b·∫•m t√°i s·ª≠ d·ª•ng
class ControlButton extends StatelessWidget {
  final IconData icon;
  final VoidCallback onTap;
  final Color color;
  final bool isEndCall;

  const ControlButton({
    super.key,
    required this.icon,
    required this.onTap,
    required this.color,
    this.isEndCall = false,
  });

  @override
  Widget build(BuildContext context) {
    return InkWell(
      onTap: onTap,
      borderRadius: BorderRadius.circular(30),
      child: Container(
        padding: EdgeInsets.all(isEndCall ? 15 : 12),
        decoration: BoxDecoration(
          color: isEndCall ? Colors.red : Colors.grey[700],
          shape: BoxShape.circle,
        ),
        child: Icon(icon, color: color, size: 24),
      ),
    );
  }
}
```

---

## 16.8. T√≠ch h·ª£p Screen Sharing

ƒê·ªÉ chia s·∫ª m√†n h√¨nh, b·∫°n c·∫ßn l·∫•y stream m√†n h√¨nh (`getDisplayMedia`) v√† thay th·∫ø track video hi·ªán t·∫°i v√†o PeerConnection.

```dart
// Th√™m v√†o WebRTCManager
Future<void> startScreenShare() async {
  // Ch·ªâ ho·∫°t ƒë·ªông t·ªët tr√™n Web. Mobile c·∫ßn c√°c plugin kh√°c ho·∫∑c custom channels.
  final stream = await navigator.mediaDevices.getDisplayMedia({
    'video': {'cursor': 'always'},
    'audio': false
  });
  
  // L·∫•y Video Track c·ªßa screen share
  final videoTrack = stream.getVideoTracks()[0];
  
  // Thay th·∫ø (Replace) track trong PeerConnection
  // C·∫ßn t√¨m sender c·ªßa track video c≈© v√† replace
  // Code chi ti·∫øt c√≥ trong th∆∞ vi·ªán flutter_webrtc examples
}

Future<void> stopScreenShare() {
  // Switch back to camera
}
```

---

## 16.9. Giao di·ªán T·ªëi ∆∞u cho Video Calls

1.  **Orientation Lock:** Kh√≥a xoay m√†n h√¨nh (Landscape cho Group Call, Portrait cho 1-1) ƒë·ªÉ tr√°nh vi·ªác Camera xoay theo thi·∫øt b·ªã g√¢y l·ªói render.
    ```dart
    SystemChrome.setPreferredOrientations([
      DeviceOrientation.portraitUp,
      DeviceOrientation.portraitDown,
    ]);
    ```
2.  **Wakelock:** Gi·ªØ m√†n h√¨nh s√°ng khi ƒëang g·ªçi video.
    ```dart
    WakelockPlus.enable(); // D√πng wakelock_plus package
    ```
3.  **Picture-in-Picture (PiP):** N·∫øu ng∆∞·ªùi d√πng b·∫•m Home tr√™n Mobile, h√£y hi·ªÉn th·ªã Picture-in-Picture (th∆∞ vi·ªán `flutter_pip`). ƒêi·ªÅu n√†y ƒë√≤i h·ªèi backend SFU (Pion) ti·∫øp t·ª•c g·ª≠i stream.

---

## 16.10. B·∫£o m·∫≠t & UI Feedback

*   **Recording Indicator:** N·∫øu `is_encrypted = false` (Opt-out Mode), UI ph·∫£i hi·ªÉn th·ªã **Icon Red Dot** ho·∫∑c nh·∫•p nh√°y ·ªü g√≥c m√†n h√¨nh ƒë·ªÉ b√°o cho user bi·∫øt cu·ªôc g·ªçi c√≥ th·ªÉ ƒëang ƒë∆∞·ª£c ghi √¢m.
*   **Secure Connection:** Hi·ªÉn th·ªã bi·ªÉu t∆∞·ª£ng ·ªï kh√≥a v√†ng (üîí) khi E2EE ƒëang ho·∫°t ƒë·ªông.

---

*Li√™n k·∫øt ƒë·∫øn t√†i li·ªáu ti·∫øp theo:* `flutter/edge-ai-setup.md`